{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocesamiento de los datos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para lograr implementar cualquier modelo con éxito y resolver un problema, es importante realizar un preprocesamiento a los datos que se vayan a usar. Este proceso siempre se debe emplear porque los datos pueden estar sucios, contener ruido, datos faltantes, caracteres especiales, signos de puntuación, entre otras, los cuales no permitirán que el modelo sea entrenado correctamente. Por tal motivo, a continuación se efectúa el proceso de verificación, limpieza, transformación y división del conjunto para entrenamiento y pruebas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "#Cargar librerias\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk \n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from wordcloud import WordCloud,STOPWORDS\n",
    "from nltk.corpus import stopwords\n",
    "from bs4 import BeautifulSoup\n",
    "import re,string,unicodedata\n",
    "\n",
    "from nltk.tokenize import word_tokenize,sent_tokenize\n",
    "from nltk.tokenize.toktok import ToktokTokenizer\n",
    "\n",
    "#Modelos\n",
    "from sklearn.linear_model import LogisticRegression,SGDClassifier\n",
    "from sklearn.metrics import classification_report,confusion_matrix,accuracy_score\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El conjunto de datos que utilizara para el proceso de análisis de sentimientos en reseñas de películas, está conformado por 50 mil datos. El conjunto de datos está constituido por dos columnas (review, sentiment). Para cargar los datos, se utiliza la librería Pandas y se muestra los 10 primeros datos que contiene el datset. La columna review contiene información con datos sucios y ruidos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_uuid": "4c593c17588723c0b0b0f19851cb70a8447ced76",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>One of the other reviewers has mentioned that ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I thought this was a wonderful way to spend ti...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Basically there's a family where a little boy ...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Probably my all-time favorite movie, a story o...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>I sure would like to see a resurrection of a u...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>This show was an amazing, fresh &amp; innovative i...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Encouraged by the positive comments about this...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>If you like original gut wrenching laughter yo...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review sentiment\n",
       "0  One of the other reviewers has mentioned that ...  positive\n",
       "1  A wonderful little production. <br /><br />The...  positive\n",
       "2  I thought this was a wonderful way to spend ti...  positive\n",
       "3  Basically there's a family where a little boy ...  negative\n",
       "4  Petter Mattei's \"Love in the Time of Money\" is...  positive\n",
       "5  Probably my all-time favorite movie, a story o...  positive\n",
       "6  I sure would like to see a resurrection of a u...  positive\n",
       "7  This show was an amazing, fresh & innovative i...  negative\n",
       "8  Encouraged by the positive comments about this...  negative\n",
       "9  If you like original gut wrenching laughter yo...  positive"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Muestra los 10 primeros review\n",
    "data=pd.read_csv('IMDB Dataset.csv')\n",
    "print(data.shape)\n",
    "data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'A wonderful little production. <br /><br />The filming technique is very unassuming- very old-time-BBC fashion and gives a comforting, and sometimes discomforting, sense of realism to the entire piece. <br /><br />The actors are extremely well chosen- Michael Sheen not only \"has got all the polari\" but he has all the voices down pat too! You can truly see the seamless editing guided by the references to Williams\\' diary entries, not only is it well worth the watching but it is a terrificly written and performed piece. A masterful production about one of the great master\\'s of comedy and his life. <br /><br />The realism really comes home with the little things: the fantasy of the guard which, rather than use the traditional \\'dream\\' techniques remains solid then disappears. It plays on our knowledge and our senses, particularly with the scenes concerning Orton and Halliwell and the sets (particularly of their flat with Halliwell\\'s murals decorating every surface) are terribly well done.'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Imprime el review que se encuentra en la posición 4 \n",
    "data['review'][1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "453c3fd238f62ab8f649eb01771817e25bc0c77d"
   },
   "source": [
    "### Verificar datos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una vez cargados los datos se verifica que el dataset no contenga valores nulos. Y para esto, se utiliza la función isnull para la comprobación. Esta función devolverá \"True\" si encuentra componentes faltantes y \"False\" para los componentes que no faltan. Finalmente, se contará todos los valores \"True\" y como se puede observar, el conteo dio 0, es decir, no existe valores nulos en todo el dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "review       0\n",
       "sentiment    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Se verifica si existe valores nullos en el dataset\n",
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "classes = data.sentiment.unique()\n",
    "counts = []\n",
    "\n",
    "for i in classes:\n",
    "  count = len(data[data.sentiment==i])\n",
    "  counts.append(count)\n",
    "\n",
    "plt.bar(['negative', 'positive'], counts)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "90da29c3b79f46f41d7391a2a116065b616d0fac"
   },
   "source": [
    "### Tokenizar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La tokenización sirve para encontrar y comprender patrones en el texto, el cual es útil para realizar el proceso de análisis de sentimiento. Este proceso es base para derivación y lematización del texto. Por tal motivo, en la siguiente línea de código se emplea el token y se configura las palabras vacías en el idioma en inglés."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "_uuid": "f000c43d91f68f6668539f089c6a54c5ce3bd819"
   },
   "outputs": [],
   "source": [
    "#Tokenización de texto\n",
    "tokenizer=ToktokTokenizer()\n",
    "\n",
    "#Configuración de palabras vacías en inglés\n",
    "stopword_list=nltk.corpus.stopwords.words('english')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "328b6e5977da3e055ad4b2e11a31e5e12ccf3b16"
   },
   "source": [
    "### Eliminar etiquetas html y ruido en el texto"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En las siguientes líneas de código se realiza el proceso de limpieza de los datos. Se desarrolla una función para eliminar cualquier elemento HTML que exista en los review. Otra función para eliminar expresiones regulares, como lo son corchetes, llaves, asteriscos, comillas, entre otros. También se elimina texto ruidoso y finalmente, la eliminación de caracteres especiales."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "_uuid": "6f6fcafbdadcdcb0c164e37d71fb9d1623f74d0a"
   },
   "outputs": [],
   "source": [
    "#Eliminar etiquetas de HTML\n",
    "def etiqueta_html(text):\n",
    "    soup = BeautifulSoup(text, \"html.parser\")\n",
    "    return soup.get_text()\n",
    "\n",
    "#Eliminar algunas expresiones\n",
    "def eliminar_corchetes(text):\n",
    "    return re.sub('\\[[^]]*\\]', '', text)\n",
    "\n",
    "#Elimina texto ruidoso\n",
    "def eliminar_ruido(text):\n",
    "    text = etiqueta_html(text)\n",
    "    text = eliminar_corchetes(text)\n",
    "    return text\n",
    "\n",
    "#Aplicar la función denoise_text en la columna de review\n",
    "data['review']=data['review'].apply(eliminar_ruido)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "88117b74761d1047924d6d70f76642faa0e706ac"
   },
   "source": [
    "### Eliminación de caracteres especiales "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "_uuid": "219da72b025121fd98081df50ae0fcaace10cc9d"
   },
   "outputs": [],
   "source": [
    "#Definir función para eliminar caracteres especiales\n",
    "def eliminar_caracteres_especiales(text, remove_digits=True):\n",
    "    pattern=r'[^a-zA-z0-9\\s]'\n",
    "    text=re.sub(pattern,'',text)\n",
    "    return text\n",
    "\n",
    "#Aplicar la función remove_special_characters en la columna review\n",
    "data['review']=data['review'].apply(eliminar_caracteres_especiales)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "3b66eeabd5b7b8c251f8b8ddf331140a64bcd514"
   },
   "source": [
    "### Stemming"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La implementación del Stemming se encarga de reducir las palabras a su raíz. Y es útil para asignar varias palabras a una palabra base en específico, esto no solo se hace con palabras, sino también con oraciones. Por tal motivo, en la siguiente línea de código se emplea Steamming en el texto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "_uuid": "2295f2946e0ab74c220ad538d0e7adc04d23f697"
   },
   "outputs": [],
   "source": [
    "#Stemming del texto\n",
    "def simple_stemmer(text):\n",
    "    ps=nltk.porter.PorterStemmer()\n",
    "    text= ' '.join([ps.stem(word) for word in text.split()])\n",
    "    return text\n",
    "\n",
    "#Aplicar la función en la columna review \n",
    "data['review']=data['review'].apply(simple_stemmer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "e83107e4a281d84d7ae42b4e2c8d81b7ece438e4"
   },
   "source": [
    "### Eliminar palabras vacías"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Con el proceso de tokenización, se desarrolla una función que elimina todas las palabras vacias y se aplica el metodo en la columna review."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "_uuid": "5dbff82b4d2d188d8777b273a75d8ac714d38885"
   },
   "outputs": [],
   "source": [
    "#establecer palabras vacías en inglés\n",
    "stop=set(stopwords.words('english'))\n",
    "\n",
    "#eliminando las palabras vacías\n",
    "def remove_stopwords(text, is_lower_case=False):\n",
    "    tokens = tokenizer.tokenize(text)\n",
    "    tokens = [token.strip() for token in tokens]\n",
    "    if is_lower_case:\n",
    "        filtered_tokens = [token for token in tokens if token not in stopword_list]\n",
    "    else:\n",
    "        filtered_tokens = [token for token in tokens if token.lower() not in stopword_list]\n",
    "    filtered_text = ' '.join(filtered_tokens)    \n",
    "    return filtered_text\n",
    "\n",
    "#Aplicar la función\n",
    "data['review']=data['review'].apply(remove_stopwords)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "b35e7499291173119ed42287deac6f0cd96516e1"
   },
   "source": [
    "### Normalización de los review"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una vez terminado el proceso de limpieza de los datos, se emplea la normalización, es decir, estandariza todos los datos a un solo nive (palabras en minusculas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "_kg_hide-output": true,
    "_uuid": "b20c242bd091929ca896ea2c6e936ca00efe6ecf"
   },
   "outputs": [],
   "source": [
    "#normalized train reviews\n",
    "norm_train_reviews=data.review[:35000]\n",
    "\n",
    "#Normalized test reviews\n",
    "norm_test_reviews=data.review[35000:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modelo Bags of words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para realizar análisis de sentimiento se necesita crear una bolsa de palabras. El modelo Bag of Words es utilizado para representar los datos de prueba. Este método es empleado para PLN y IR. Para implementar este modelo se genera un vector de bolsas de palabras y después se hace un ajuste de los datos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "_uuid": "35cf9dcefb40b2dc520c5b0d559695324c46cc04"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ajuste de los datos de entrenamiento: (35000, 5533754)\n",
      "Ajuste de los datos de prueba: (15000, 5533754)\n"
     ]
    }
   ],
   "source": [
    "#Vectorizar para armar bolsa de palabras\n",
    "cv=CountVectorizer(min_df=0,max_df=1,binary=False,ngram_range=(1,3))\n",
    "\n",
    "#Transformar datos\n",
    "cv_train_reviews=cv.fit_transform(norm_train_reviews)\n",
    "#transformed test reviews\n",
    "cv_test_reviews=cv.transform(norm_test_reviews)\n",
    "\n",
    "print('Ajuste de los datos de entrenamiento:',cv_train_reviews.shape)\n",
    "print('Ajuste de los datos de prueba:',cv_test_reviews.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "52371868f05ff9cf157280c5acf0f5bc71ee176d"
   },
   "source": [
    "### Modelo TFIDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "_uuid": "afe6de957339921e05a6faeaf731f2272fd31946",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ajuste de los datos de entrenamiento:: (35000, 5533754)\n",
      "Ajuste de los datos de prueba: (15000, 5533754)\n"
     ]
    }
   ],
   "source": [
    "#Vectorizar Tfidf vectorizer\n",
    "tv=TfidfVectorizer(min_df=0,max_df=1,use_idf=True,ngram_range=(1,3))\n",
    "\n",
    "#Transformar datos y hacer fit\n",
    "tv_train_reviews=tv.fit_transform(norm_train_reviews)\n",
    "\n",
    "#transformed test reviews\n",
    "tv_test_reviews=tv.transform(norm_test_reviews)\n",
    "\n",
    "print('Ajuste de los datos de entrenamiento::',tv_train_reviews.shape)\n",
    "print('Ajuste de los datos de prueba:',tv_test_reviews.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "803e92b25faa738b10928a91de72d177d8dddf85"
   },
   "source": [
    "### Transformación del etiquetado a datos binarios"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una vez ya procesado los datos pertenecientes a la columna review, ahora solo falta la columna sentiment. En el caso de este dataset, la columna sentiment únicamente tiene dos valores: positive, negative. Y como tal, estos valores se los pueden convertir en números binarios, en donde el 0 representa a los negativos y el 1 a los positivos. La función LabelBinariser hace este proceso de binarización."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "_uuid": "60f5d496ce4109d1cdbf08f4284d4d26efd93922"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000,)\n"
     ]
    }
   ],
   "source": [
    "#Función para convertir en binarios\n",
    "lb=LabelBinarizer()\n",
    "\n",
    "#transformación de los datos \n",
    "data['sentiment']=lb.fit_transform(data['sentiment'])\n",
    "\n",
    "print(data['sentiment'].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "21a80c94fb42e14391c627710c5d796c40aa7dde"
   },
   "source": [
    "### Dividir el conjunto de las Y."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "_kg_hide-output": true,
    "_uuid": "ca1e4cc917265ac98a72c37cffe57f27e9897408"
   },
   "outputs": [],
   "source": [
    "train_sentiments=data['sentiment'][:35000]\n",
    "test_sentiments=data['sentiment'][35000:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Con el siguiente codigo se genera un nuevo archivo csv con los datos limpios. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>one review ha mention watch 1 oz episod youll ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>wonder littl product film techniqu veri unassu...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>thought thi wa wonder way spend time hot summe...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>basic famili littl boy jake think zombi hi clo...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>petter mattei love time money visual stun film...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review  sentiment\n",
       "0  one review ha mention watch 1 oz episod youll ...          1\n",
       "1  wonder littl product film techniqu veri unassu...          1\n",
       "2  thought thi wa wonder way spend time hot summe...          1\n",
       "3  basic famili littl boy jake think zombi hi clo...          0\n",
       "4  petter mattei love time money visual stun film...          1"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#ruta = \"review_limpios.csv\"\n",
    "#data.to_csv(ruta)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Selección de caracteristicas "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como se puede observar, mi dataset solo tienen una caracteristica, por lo tanto, no aplico ningun algoritmo para selección de caracteristicas. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Qué modelo de ML/DL/DM usted aplicará a su proyecto para ser resuelto?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El modelo principal que se aplicara para analizar sentimiento en el texto, es un algoritmo de Deep Learning basico, es cual es LSTM. Este modelo permite tener mayor precisión gracias a su memoria a largo plazo a comparación de los modelos tradicionales. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Con qué modelos comparará ese modelo y por qué?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los modelos escogidos para comparar el modelo de LSTM son: regresión logística y SVM. Estos modelos se escogieron porque según todos los artículos revisados, la mayoría utilizaban dichos modelos y obtuvieron buenos resultados de acurracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cuáles son los hyperparameters que utilizará para cada modelo? Interprete los resultados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SVM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En el modelo SVM, el primer hiperparámetro que se debería escoger son los nucleas (kernel). Estos núcleos pueden ser de varios tipos, y los que comúnmente se usan son los: linear, poly, RBF y sigmoid. En el caso de que no se especifique el tipo de de núcleo a utilizar, automáticamente el algoritmo utilizara RBF.\n",
    "\n",
    "Otro hiperparámetro de SVM también es la penalización, que viene siendo el valor de C. Este valor, como se mencionó anteriormente, también controla la fuerza de penalización; estos números tienen que ser de tipo flotante, es decir, decimales. En el caso de que no se especifique el valor de C, se tomara el numero predeterminado que es 1.0."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "param_grid = {\n",
    "    'kernel': ['poly', 'rbf', 'sigmoid'],\n",
    "    'C': [50, 10, 1.0, 0.1, 0.01],\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Regressión logistica"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los hiperparámetros de regresión logísticas realmente no tienen una forma criticar para ajustar los parámetros. Muchas veces se puede observar algunas diferencias que puede ser útiles en la convergencia del modelo o el rendimiento dependiendo del solucionador (solver). El solver puede ser de tipo: newton-cg, lbfgs, liblinear, sag y saga. Para poder regularizar los solucionadores se utiliza el hiperparámetro penalización (penalty), que puden ser de tipo: none (no añade penalización), L2 ( es el tipo de penalización predeterminada), L1 (añade un término de penalización L1) y elasticnet (añade términos de penalización L1 y L2).\n",
    "\n",
    "Los regularizadores se puden utilizar dependiendo el tipo de solucionador, por ejemplo, los solucionadores newton-cg, sag y lbfgs solo admiten la regularización L2 con formulación primaria o sin regularización. El solucionador liblineal admite la regularización de L1 y L2, con una formulación dual solo para la penalización de L2. La regularización de Elastic-Net solo es compatible con el solucionador saga. Después se encuentra el hiperparámetro C, el cual controla la potencia o fuerza de la penalización. Estos valores pueden estar entre 100, 10, 1.0, 0.1 y 0.01.\n",
    "\n",
    "El hiperparámetro max_iter se puede definir para controlar el número máximo de interacciones que se necesitan para el solucionar converja. El max_iter puede tener cualquier número entero, pero el numero predeterminado es 100. El random_state es otro tipo de hiperparámetro que es utilizado para mezclar datos, pero, solo es compatible para solucionadores: sag, saga o liblinear'int. Estos pueden ser de tipo: RandomState instance, none, es cual es el predeterminado y cualquier número entero. Estos dos últimos hiperparámetros se los puede utilizar dependiendo el solucionador que se elija."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'imputer__strategy': ['mean', 'median', 'constant'],\n",
    "    'imputer__add_indicator': [True, False],\n",
    "    'regressor__alpha': [10, 100, 200],\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LSTM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El algoritmo de LST o Redes neuronales recurrentes, tienen varios parámetros que se pueden ajustar, pero solo se definirán los más importantes. El hiperparámetro en donde se define los nodos a utilizar y capas ocultas son unos de los parámetros más relevantes. Para este parámetro no existe un número final definido para usar, esto depende de cada problema en particular. Como conocimiento general la utilización de una capa oculta es suficiente para problemas simples. Como segundo parámetro se puede mencionar la elección del número en una capa densa, la cual es la más utilizadas. Estas capas mejoran la precisión del modelo, y se tiene visto que entre 5 a 10 unidades por cada una de capa es una base.\n",
    "\n",
    "Otros de los parámetros es el abandono (dropout), el cual ayuda a evitar que haya un sobreajuste en el modelo por los datos de entrenamiento. El valor de dropout debe estar definido entre 0.2 y 0.5, para lograr mantener la presión del modelo y evitar un sobreajuste. Y por último, otro de los parámetros más importantes es el número de épocas (Batch Size), este establece un número de muestras en las que se enfoca primero antes de que trabajen o se actualicen los parámetros internos. El valor predeterminado para este parámetro es de 32, pero para experimentar se puede variar entre 64, 128 y 256."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'Dense': [5, 6, 7, 8, 9, 10],\n",
    "    'Hidden Layers': [1, 2],\n",
    "    'Dropout': [0.2, 0.3, 0.4, 0.5],\n",
    "    'Batch Size': [1, 2, 3, 4, 5],\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Qué métricas utilizará para evaluar su modelo? Comente sobre cada métrica y qué valor espera."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La metrica principal que se utilizara para comparar los modelos es el acurracy de cada uno. Pero para obtener mayor detalle de la clasificación que realiza cada modelos, se generar un reporte de clasificación. El reporte de clasificación obtiene información sobre la presición, recall, f1 score y support. El acurry en la medida que se obtinene para ver que tan serca esta de tener el modelos valores reales. La presición, el recall, F1-score son metricas adicionales que puede obtner para observar con mayor detalle del modelo. \n",
    "Los valores en las metricas puede variar dependiendo del modelo. Pero se espera tener valores mayores al 70%. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
